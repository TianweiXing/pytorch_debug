{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\";  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset import CLEVR, collate_data, transform\n",
    "from model import MACNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400001, 300)\n",
      "Size of word embedding matrix:  (400001, 300)\n"
     ]
    }
   ],
   "source": [
    "import embedding as ebd\n",
    "embedding_matrix = ebd.load()\n",
    "print(embedding_matrix.shape)\n",
    "# embedding_matrix = ebd.load()\n",
    "print('Size of word embedding matrix: ',embedding_matrix.shape)\n",
    "num_words = 400001\n",
    "embedding_dim = 300\n",
    "seq_length = 31#data_q_valid.shape[1] \n",
    "\n",
    "num_hidden_lstm = 128\n",
    "output_dim =128\n",
    "dropout_rate = 0.5\n",
    "\n",
    "sen_dim = 77\n",
    "sen_win_len = 1800 \n",
    "sen_channel = 1\n",
    "num_feat_map = 64\n",
    "\n",
    "num_classes = 28#data_a_valid.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(400001, 300)\n",
    "        # Embedding layer: loading weights\n",
    "        embedding_matrix = ebd.load()\n",
    "        print(embedding_matrix.shape)\n",
    "        self.embed.weight.data = torch.Tensor(embedding_matrix)\n",
    "        self.embed.weight.requires_grad = False\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(300, 128, 1, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(128, 128, 1, batch_first=True)\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(128, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 28)\n",
    "\n",
    "\n",
    "    def forward(self, question):\n",
    "        batch_size = question.size()[0]\n",
    "        \n",
    "        embed = self.embed(question)\n",
    "#         print(embed.shape)\n",
    "        lstm_out, _ = self.lstm1(embed)\n",
    "        lstm_out = F.dropout(lstm_out, 0.5)\n",
    "#         print(lstm_out.shape)\n",
    "        lstm_out, _ = self.lstm2(lstm_out)\n",
    "        lstm_out = F.dropout(lstm_out, 0.5)\n",
    "#         print(lstm_out.shape)\n",
    "        \n",
    "        x = lstm_out[:,-1]\n",
    "#         print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400001, 300)\n"
     ]
    }
   ],
   "source": [
    "lstm_net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (embed): Embedding(400001, 300)\n",
       "  (lstm1): LSTM(300, 128, batch_first=True)\n",
       "  (lstm2): LSTM(128, 128, batch_first=True)\n",
       "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(11, 31)\n",
    "x = x.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_net(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "class My_Data2(data.Dataset):\n",
    "    def __init__(self,  split='train', transform=None):\n",
    "        \n",
    "        processed_test_data_path = 'test_data.npz'\n",
    "    \n",
    "        npzfile = np.load(processed_test_data_path)\n",
    "#         print(npzfile.files)\n",
    "#         self.data_s_split = npzfile['s_' + split]#$[3011:3031]\n",
    "        self.data_a_split = npzfile['a_' + split]#[3011:3031]\n",
    "        self.data_q_split = npzfile['q_' + split]#[3011:3031]\n",
    "        \n",
    "        # adjust dimension\n",
    "        self.data_a_split = self.data_a_split.argmax(1)\n",
    "#         self.data_s_split = np.expand_dims(self.data_s_split, -1)  \n",
    "#         self.data_s_split = np.swapaxes(self.data_s_split,1,2)\n",
    "#         self.data_s_split = np.expand_dims(self.data_s_split, -1)\n",
    "        self.split = split  # train or val\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         data_s = self.data_s_split[index]\n",
    "        data_q = self.data_q_split[index]\n",
    "        data_a = self.data_a_split[index]\n",
    "        return data_q, len(data_q), data_a\n",
    "#         return data_s, data_q, len(data_q), data_a\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_a_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(epoch):\n",
    "#     clevr = CLEVR(sys.argv[1], transform=transform)\n",
    "    training_set = My_Data2(split='val')\n",
    "    train_set = DataLoader(\n",
    "        training_set, batch_size=batch_size, num_workers=1\n",
    "#         , collate_fn=collate_data\n",
    "    )\n",
    "\n",
    "    dataset = iter(train_set)\n",
    "    pbar = tqdm(dataset)\n",
    "    moving_loss = 0\n",
    "#     acc_accumulate = 0\n",
    "\n",
    "    net.train(True)\n",
    "    for iter_id, (question, q_len, answer) in enumerate(pbar):\n",
    "        \n",
    "#         image = image.type(torch.FloatTensor) # change data type: double to float\n",
    "        q_len = q_len.tolist()\n",
    "        question = question.type(torch.LongTensor)\n",
    "        \n",
    "        question, answer = (\n",
    "            question.to(device),\n",
    "            answer.to(device),\n",
    "        )\n",
    "\n",
    "        net.zero_grad()\n",
    "        output = net(question)\n",
    "        loss = criterion(output, answer)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct = output.detach().argmax(1) == answer\n",
    "        correct = torch.tensor(correct, dtype=torch.float32).sum() / batch_size\n",
    "        \n",
    "        # correct is the acc for current batch, moving_loss is the acc for previous batches\n",
    "        if moving_loss == 0:\n",
    "            moving_loss = correct\n",
    "        else:\n",
    "            moving_loss = (moving_loss * iter_id + correct)/(iter_id+1)\n",
    "#             moving_loss = moving_loss * 0.99 + correct * 0.01\n",
    "\n",
    "        pbar.set_description(\n",
    "            'Epoch: {}; Loss: {:.5f}; Current_Acc: {:.5f}; Total_Acc: {:.5f}'.format(\n",
    "                epoch + 1, loss.item(), correct, moving_loss\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "def valid(epoch):\n",
    "#     clevr = CLEVR(sys.argv[1], 'val', transform=None)\n",
    "    training_set = My_Data2(split='val')\n",
    "    valid_set = DataLoader(\n",
    "        training_set, batch_size=batch_size, num_workers=1\n",
    "#         , collate_fn=collate_data\n",
    "    )\n",
    "    \n",
    "    dataset = iter(valid_set)\n",
    "\n",
    "    net.train(False)\n",
    "    family_correct = Counter()\n",
    "    family_total = Counter()\n",
    "    loss_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for  question, q_len, answer in tqdm(dataset):\n",
    "            \n",
    "            family = [1]*len(question)\n",
    "#             image = image.type(torch.FloatTensor) # change data type: double to float\n",
    "            q_len = q_len.tolist()\n",
    "            question = question.type(torch.LongTensor)\n",
    "            \n",
    "            question = question.to(device)\n",
    "\n",
    "            output = net(question)\n",
    "            loss = criterion(output, answer.to(device))\n",
    "            \n",
    "            loss_total = loss_total + loss\n",
    "            correct = output.detach().argmax(1) == answer.to(device)\n",
    "            for c, fam in zip(correct, family):\n",
    "                if c:\n",
    "                    family_correct[fam] += 1\n",
    "                family_total[fam] += 1\n",
    "                \n",
    "\n",
    "    print(\n",
    "        'Avg Acc: {:.5f}; Avg Loss: {:.5f}'.format(\n",
    "            sum(family_correct.values()) / sum(family_total.values()),\n",
    "            loss_total / sum(family_total.values())\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print('%d / %d'%(sum(family_correct.values()), sum(family_total.values())))\n",
    "    return sum(family_correct.values()) / sum(family_total.values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "n_epoch = 20\n",
    "dim = 512\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400001, 300)\n"
     ]
    }
   ],
   "source": [
    "net = Net().to(device)\n",
    "# net_running = Net().to(device)\n",
    "# accumulate(net_running, net, 0)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========0 epoch ==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/320 [00:00<?, ?it/s]/home/tianwei/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "Epoch: 1; Loss: 0.64951; Current_Acc: 0.65625; Total_Acc: 0.59639: 100%|██████████| 320/320 [00:06<00:00, 49.30it/s]\n",
      "100%|██████████| 320/320 [00:01<00:00, 259.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Acc: 0.44164; Avg Loss: 0.02848\n",
      "9035 / 20458\n",
      "==========1 epoch ==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2; Loss: 0.71768; Current_Acc: 0.62500; Total_Acc: 0.64038: 100%|██████████| 320/320 [00:06<00:00, 49.99it/s]\n",
      "100%|██████████| 320/320 [00:01<00:00, 232.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Acc: 0.44046; Avg Loss: 0.02949\n",
      "9011 / 20458\n",
      "==========2 epoch ==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3; Loss: 0.73796; Current_Acc: 0.29688; Total_Acc: 0.63608: 100%|██████████| 320/320 [00:05<00:00, 58.88it/s]\n",
      "100%|██████████| 320/320 [00:01<00:00, 255.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Acc: 0.44027; Avg Loss: 0.02949\n",
      "9007 / 20458\n",
      "==========3 epoch ==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4; Loss: 0.79746; Current_Acc: 0.00000; Total_Acc: 0.64853: 100%|██████████| 320/320 [00:06<00:00, 49.09it/s]\n",
      "100%|██████████| 320/320 [00:01<00:00, 268.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Acc: 0.31489; Avg Loss: 0.02873\n",
      "6442 / 20458\n",
      "==========4 epoch ==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5; Loss: 0.82587; Current_Acc: 0.00000; Total_Acc: 0.63262: 100%|██████████| 320/320 [00:06<00:00, 50.86it/s]\n",
      "100%|██████████| 320/320 [00:01<00:00, 256.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Acc: 0.32154; Avg Loss: 0.02883\n",
      "6578 / 20458\n",
      "==========5 epoch ==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6; Loss: 0.76634; Current_Acc: 0.62500; Total_Acc: 0.64609: 100%|██████████| 320/320 [00:06<00:00, 49.31it/s]\n",
      "100%|██████████| 320/320 [00:01<00:00, 254.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Acc: 0.44169; Avg Loss: 0.02699\n",
      "9036 / 20458\n",
      "==========6 epoch ==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7; Loss: 0.81021; Current_Acc: 0.00000; Total_Acc: 0.70522: 100%|██████████| 320/320 [00:06<00:00, 49.16it/s]\n",
      "100%|██████████| 320/320 [00:01<00:00, 256.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Acc: 0.31469; Avg Loss: 0.03069\n",
      "6438 / 20458\n",
      "==========7 epoch ==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8; Loss: 0.81189; Current_Acc: 0.00000; Total_Acc: 0.63398: 100%|██████████| 320/320 [00:06<00:00, 49.44it/s]\n",
      "100%|██████████| 320/320 [00:01<00:00, 263.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Acc: 0.32203; Avg Loss: 0.03045\n",
      "6588 / 20458\n",
      "==========8 epoch ==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9; Loss: 0.77047; Current_Acc: 0.07812; Total_Acc: 0.65566: 100%|██████████| 320/320 [00:06<00:00, 48.61it/s]\n",
      "100%|██████████| 320/320 [00:01<00:00, 275.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Acc: 0.43978; Avg Loss: 0.02924\n",
      "8997 / 20458\n",
      "==========9 epoch ==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 10; Loss: 0.72677; Current_Acc: 0.65625; Total_Acc: 0.66211: 100%|██████████| 320/320 [00:06<00:00, 49.81it/s]\n",
      "100%|██████████| 320/320 [00:01<00:00, 249.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Acc: 0.44164; Avg Loss: 0.02765\n",
      "9035 / 20458\n",
      "==========10 epoch ==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 11; Loss: 0.68184; Current_Acc: 0.65625; Total_Acc: 0.66538: 100%|██████████| 320/320 [00:06<00:00, 49.64it/s] \n",
      "100%|██████████| 320/320 [00:01<00:00, 248.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Acc: 0.44164; Avg Loss: 0.02666\n",
      "9035 / 20458\n",
      "==========11 epoch ==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 12; Loss: 0.16241; Current_Acc: 1.00000; Total_Acc: 0.59541:  73%|███████▎  | 235/320 [00:04<00:01, 49.47it/s]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/tianwei/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-ef45764fa1d7>\", line 6, in <module>\n",
      "    train(epoch)\n",
      "  File \"<ipython-input-12-7add86f37276>\", line 35, in train\n",
      "    output = net(question)\n",
      "  File \"/home/tianwei/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-6-61f8ec9d175c>\", line 32, in forward\n",
      "    lstm_out, _ = self.lstm2(lstm_out)\n",
      "  File \"/home/tianwei/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/tianwei/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/torch/nn/modules/rnn.py\", line 559, in forward\n",
      "    self.dropout, self.training, self.bidirectional, self.batch_first)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tianwei/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tianwei/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/tianwei/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/tianwei/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/tianwei/anaconda3/envs/tf_gpu/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/tianwei/anaconda3/envs/tf_gpu/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/tianwei/anaconda3/envs/tf_gpu/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/tianwei/anaconda3/envs/tf_gpu/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/tianwei/anaconda3/envs/tf_gpu/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/tianwei/anaconda3/envs/tf_gpu/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/tianwei/anaconda3/envs/tf_gpu/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "acc_best = 0.0\n",
    "\n",
    "for epoch in range(100):\n",
    "# for epoch in range(n_epoch):\n",
    "    print('==========%d epoch =============='%(epoch))\n",
    "    train(epoch)\n",
    "    acc = valid(epoch) # inference on: validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s_train', 'q_train', 'a_train', 's_val', 'q_val', 'a_val', 'train_ind', 'valid_ind']\n",
      "\n",
      "Validation:\n",
      "Question matrix:  (20458, 31)\n",
      "Answer matrix:  (20458, 27)\n",
      "[9035. 6438. 1978. 1258.  285.   78.   91.   84.   34.  111.   95.   85.\n",
      "  102.  102.  103.   60.   96.  103.  152.   52.   42.   56.   18.    0.\n",
      "    0.    0.    0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "processed_test_data_path = '../SQA_model/618_processed_data/s123_1800_600_split.npz'\n",
    "npzfile = np.load(processed_test_data_path)\n",
    "print(npzfile.files)\n",
    "\n",
    "# data_s_valid = npzfile['s_val']\n",
    "data_a_valid = npzfile['a_val']\n",
    "data_q_valid = npzfile['q_val']\n",
    "\n",
    "print('\\nValidation:')\n",
    "# print('Sensory matrix: ', data_s_valid.shape)\n",
    "print('Question matrix: ', data_q_valid.shape)\n",
    "print('Answer matrix: ', data_a_valid.shape)\n",
    "\n",
    "print(data_a_valid.sum(axis = 0))\n",
    "\n",
    "\n",
    "# np.savez('test_data.npz', s_val = data_s_valid,\n",
    "#                           q_val = data_q_valid,\n",
    "#                           a_val = data_a_valid)\n",
    "\n",
    "np.savez('test_data.npz', \n",
    "                          q_val = data_q_valid,\n",
    "                          a_val = data_a_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpy",
   "language": "python",
   "name": "tf_gpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
